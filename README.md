# ğŸ—ï¸ AI Construction Analysis API

API profesional diseÃ±ada para la auditorÃ­a y anÃ¡lisis de datos de obras civiles mediante Inteligencia Artificial. El sistema transforma reportes de obra crudos en informaciÃ³n estructurada y accionable, detectando riesgos de seguridad y desviaciones de cronograma.

---

## ğŸ“¸ Arquitectura del Sistema

La API sigue un patrÃ³n de **Persistencia en Cascada** y **AuditorÃ­a de IA**, asegurando que ningÃºn dato se pierda incluso si el proveedor de IA falla.



---

## ğŸš€ Hitos del Proyecto

### 1. NormalizaciÃ³n de Datos (Paso 2)
A diferencia de un sistema simple, esta API desacopla el **AnÃ¡lisis** de la **Foto de la Obra (Snapshot)**.
* **Snapshots**: Cada entrada de datos se guarda Ã­ntegramente.
* **Tablas Estructuradas**: Proyecto, Etapas, Avances y Seguridad se mapean automÃ¡ticamente a columnas SQL para permitir reportes de Business Intelligence (BI).

### 2. AuditorÃ­a LLM Pro (Paso 3)
Sistema de trazabilidad total para el control de calidad y costos:
* **Track de Tokens**: Registro de consumo de entrada y salida por cada anÃ¡lisis.
* **Latencia**: MediciÃ³n en milisegundos de la respuesta de la IA.
* **Logs de Prompts**: Almacenamiento del `System` y `User` prompt para depuraciÃ³n tÃ©cnica.

---

## ğŸ› ï¸ Stack TecnolÃ³gico

* **Backend**: FastAPI (Python 3.12+)
* **Base de Datos**: PostgreSQL
* **ORM**: SQLAlchemy 2.0 (con soporte para tipos UUID y JSON)
* **IA**: IntegraciÃ³n con modelos GPT vÃ­a `LLMClient`
* **Logging**: EstÃ¡ndar profesional con trazabilidad de errores

---

## ğŸ“‚ Estructura de Archivos

```text
.
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ db/              # ConfiguraciÃ³n de Engine y SessionLocal
â”‚   â”œâ”€â”€ models/          # Modelos de SQLAlchemy (analisis.py)
â”‚   â”œâ”€â”€ schemas/         # Validaciones de Pydantic (snapshot.py)
â”‚   â”œâ”€â”€ services/        # LÃ³gica de LLM, PromptBuilder y Webhooks
â”‚   â””â”€â”€ main.py          # Orquestador y Endpoints de la API
â”œâ”€â”€ requirements.txt     # Dependencias del proyecto
â””â”€â”€ README.md            # DocumentaciÃ³n

Gemini said
AquÃ­ tienes el cÃ³digo completo en formato Markdown listo para que lo copies y lo pegues en tu archivo README.md. He estructurado la informaciÃ³n para que se vea profesional en GitHub o cualquier plataforma de Git.

Markdown
# ğŸ—ï¸ AI Construction Analysis API

API profesional diseÃ±ada para la auditorÃ­a y anÃ¡lisis de datos de obras civiles mediante Inteligencia Artificial. El sistema transforma reportes de obra crudos en informaciÃ³n estructurada y accionable, detectando riesgos de seguridad y desviaciones de cronograma.

---

## ğŸ“¸ Arquitectura del Sistema

La API sigue un patrÃ³n de **Persistencia en Cascada** y **AuditorÃ­a de IA**, asegurando que ningÃºn dato se pierda incluso si el proveedor de IA falla.



---

## ğŸš€ Hitos del Proyecto

### 1. NormalizaciÃ³n de Datos (Paso 2)
A diferencia de un sistema simple, esta API desacopla el **AnÃ¡lisis** de la **Foto de la Obra (Snapshot)**.
* **Snapshots**: Cada entrada de datos se guarda Ã­ntegramente.
* **Tablas Estructuradas**: Proyecto, Etapas, Avances y Seguridad se mapean automÃ¡ticamente a columnas SQL para permitir reportes de Business Intelligence (BI).

### 2. AuditorÃ­a LLM Pro (Paso 3)
Sistema de trazabilidad total para el control de calidad y costos:
* **Track de Tokens**: Registro de consumo de entrada y salida por cada anÃ¡lisis.
* **Latencia**: MediciÃ³n en milisegundos de la respuesta de la IA.
* **Logs de Prompts**: Almacenamiento del `System` y `User` prompt para depuraciÃ³n tÃ©cnica.

---

## ğŸ› ï¸ Stack TecnolÃ³gico

* **Backend**: FastAPI (Python 3.12+)
* **Base de Datos**: PostgreSQL
* **ORM**: SQLAlchemy 2.0 (con soporte para tipos UUID y JSON)
* **IA**: IntegraciÃ³n con modelos GPT vÃ­a `LLMClient`
* **Logging**: EstÃ¡ndar profesional con trazabilidad de errores

---

## ğŸ“‚ Estructura de Archivos

```text
.
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ db/              # ConfiguraciÃ³n de Engine y SessionLocal
â”‚   â”œâ”€â”€ models/          # Modelos de SQLAlchemy (analisis.py)
â”‚   â”œâ”€â”€ schemas/         # Validaciones de Pydantic (snapshot.py)
â”‚   â”œâ”€â”€ services/        # LÃ³gica de LLM, PromptBuilder y Webhooks
â”‚   â””â”€â”€ main.py          # Orquestador y Endpoints de la API
â”œâ”€â”€ requirements.txt     # Dependencias del proyecto
â””â”€â”€ README.md            # DocumentaciÃ³n
âš™ï¸ InstalaciÃ³n y EjecuciÃ³n
Activar Entorno Virtual:

Bash
source venv/bin/activate
Instalar Dependencias:

Bash
pip install -r requirements.txt
Ejecutar en Desarrollo:

Bash
uvicorn app.main:app --reload
ğŸ“ Endpoints Principales
ğŸ“¥ Iniciar AnÃ¡lisis (POST /analisis/iniciar)
Recibe el JSON de la obra, persiste los datos estructurados y dispara la IA.

ğŸ” Detalle de AuditorÃ­a (GET /analisis/detalle/{id})
Devuelve la radiografÃ­a completa del proceso:

Datos originales del proyecto.

Resultado de la IA (Score de coherencia, riesgos detectados).

MÃ©tricas de auditorÃ­a (Tokens usados, modelo, tiempo).

ğŸ› ï¸ Mantenimiento (POST /mantenimiento/reset-db)
Endpoint utilitario para limpiar y recrear el esquema de base de datos durante el desarrollo.

ğŸ“Š Modelo de Datos (Snowflake Schema)
El sistema utiliza relaciones de clave forÃ¡nea (FK) vinculadas al snapshot_id, lo que permite mantener un histÃ³rico de cÃ³mo evolucionÃ³ un proyecto a travÃ©s de diferentes reportes.

Desarrollado con enfoque en escalabilidad y auditorÃ­a de IA.